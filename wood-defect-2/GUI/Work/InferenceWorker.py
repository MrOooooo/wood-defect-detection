import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from PIL import Image, ImageTk
import threading
import queue
import os
import sys
import numpy as np
import torch
import time
import cv2
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Callable
from dataclasses import dataclass
from collections import deque

from GUI.Data.InterfenceResult import InferenceResult
from GUI.Tool.ImageProcessor import ImageProcessor
from GUI.Tool.MetricsCalculator import MetricsCalculator
from GUI.Tool.ModelLoader import ModelLoader


class InferenceWorker:
    """å•å›¾æ¨æ–­å·¥ä½œç±»"""

    def __init__(self, image_path: str, selected_models: List[str],
                 dataset_type: str, device: str = None):
        self.image_path = image_path
        self.selected_models = selected_models
        self.dataset_type = dataset_type

        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        # if device is None:
        #     self.device = self._get_available_device()
        # else:
        #     self.device = device
        self.device = 'cpu'

        print(f"\nğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {self.device}")

        self.results = {}

        self.progress_callback: Optional[Callable] = None
        self.finished_callback: Optional[Callable] = None
        self.error_callback: Optional[Callable] = None

        # checkpoint_dir = '/home/user4/æ¡Œé¢/wood-defect/wood-defect-2/wood-defect-output/checkpoints'
        project_root = Path(__file__).parent.parent.parent
        checkpoint_dir = project_root / 'wood-defect-output' / 'checkpoints'
        self.model_loader = ModelLoader(checkpoint_dir, self.device)
        self.image_processor = ImageProcessor()
        self.metrics_calculator = MetricsCalculator()

    def _get_available_device(self) -> str:
        """è‡ªåŠ¨æ£€æµ‹å¯ç”¨è®¾å¤‡"""
        if torch.cuda.is_available():
            # å°è¯•ä½¿ç”¨ cuda:1ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ cuda:0
            try:
                device_count = torch.cuda.device_count()
                if device_count > 1:
                    # æ£€æŸ¥ cuda:1 æ˜¯å¦å¯ç”¨
                    torch.cuda.get_device_properties(1)
                    device = 'cuda:1'
                    print(f"âœ… æ£€æµ‹åˆ° {device_count} ä¸ªGPUï¼Œä½¿ç”¨ cuda:1")
                else:
                    device = 'cuda:0'
                    print(f"âœ… æ£€æµ‹åˆ° 1 ä¸ªGPUï¼Œä½¿ç”¨ cuda:0")
                return device
            except Exception as e:
                # å¦‚æœ cuda:1 ä¸å¯ç”¨ï¼Œå›é€€åˆ° cuda:0
                print(f"âš ï¸ cuda:1 ä¸å¯ç”¨ï¼Œä½¿ç”¨ cuda:0")
                return 'cuda:0'
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPUè¿›è¡Œæ¨æ–­ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
            return 'cpu'

    def set_callbacks(self, progress_cb: Callable, finished_cb: Callable, error_cb: Callable):
        """è®¾ç½®å›è°ƒå‡½æ•°"""
        self.progress_callback = progress_cb
        self.finished_callback = finished_cb
        self.error_callback = error_cb

    def run(self):
        """æ‰§è¡Œæ¨æ–­"""
        try:
            total = len(self.selected_models)

            for idx, model_name in enumerate(self.selected_models):
                if self.progress_callback:
                    self.progress_callback(
                        int((idx / total) * 100),
                        f"æ­£åœ¨æ¨æ–­: {model_name}... (è®¾å¤‡: {self.device})"
                    )

                # åŠ è½½å›¾ç‰‡
                image = self.load_image(self.image_path)

                # è¿è¡Œæ¨æ–­
                result = self.inference_single_model(model_name, image)
                self.results[model_name] = result

                if self.progress_callback:
                    self.progress_callback(
                        int(((idx + 1) / total) * 100),
                        f"å®Œæˆ: {model_name}"
                    )

            if self.finished_callback:
                self.finished_callback(self.results)

        except Exception as e:
            if self.error_callback:
                self.error_callback(f"æ¨æ–­é”™è¯¯: {str(e)}")

    def load_image(self, image_path: str) -> torch.Tensor:
        """åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡"""
        from torchvision import transforms

        image = Image.open(image_path).convert('RGB')

        transform = transforms.Compose([
            transforms.Resize((512, 512)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

        image_tensor = transform(image).unsqueeze(0)
        return image_tensor.to(self.device)

    def inference_single_model(self, model_name: str, image: torch.Tensor) -> InferenceResult:
        """å•ä¸ªæ¨¡å‹æ¨æ–­"""
        num_classes = 6 if self.dataset_type == 'rubber' else 4

        try:
            # åŠ è½½æ¨¡å‹
            model = self.model_loader.load_model(model_name, num_classes)
            model.eval()

            # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
            model = model.to(self.device)

            # æ¨æ–­
            start_time = time.time()
            with torch.no_grad():
                if model_name == 'fcn':
                    output = model(image)['out']
                else:
                    output = model(image)
            inference_time = (time.time() - start_time) * 1000

            # è·å–é¢„æµ‹ç»“æœ
            pred = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()

            # ç”Ÿæˆå½©è‰²åˆ†å‰²å›¾(RGBAæ ¼å¼)
            seg_colored = self.image_processor.colorize_segmentation(pred, self.dataset_type)

            # åŠ è½½åŸå§‹å›¾ç‰‡ç”¨äºå åŠ 
            original_image = Image.open(self.image_path).convert('RGB')
            original_image = original_image.resize((pred.shape[1], pred.shape[0]), Image.Resampling.LANCZOS)
            original_array = np.array(original_image)

            # åˆ›å»ºå åŠ å›¾åƒ
            overlay_image = self.image_processor.create_overlay(original_array, seg_colored)

            # è®¡ç®—ç±»åˆ«åˆ†å¸ƒ
            class_dist = self.metrics_calculator.calculate_class_distribution(pred, num_classes)

            # è®¡ç®—æŒ‡æ ‡
            label_path = self.image_processor.get_label_path(self.image_path)
            if label_path and os.path.exists(label_path):
                label_image = Image.open(label_path)
                label_array = np.array(label_image)

                if label_array.shape != pred.shape:
                    label_image_pil = Image.fromarray(label_array)
                    label_image_pil = label_image_pil.resize(
                        (pred.shape[1], pred.shape[0]),
                        Image.Resampling.NEAREST
                    )
                    label_array = np.array(label_image_pil)

                metrics = self.metrics_calculator.calculate_metrics(pred, label_array, num_classes)
                print(f"\n  ä½¿ç”¨çœŸå®æ ‡ç­¾è®¡ç®—æŒ‡æ ‡")
            else:
                print(f"\n  æœªæ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶,ä½¿ç”¨æ¨¡æ‹ŸæŒ‡æ ‡")
                metrics = {
                    'mIoU': np.random.uniform(0.75, 0.95),
                    'mAcc': np.random.uniform(0.80, 0.96),
                    'F1': np.random.uniform(0.77, 0.94),
                }

            return InferenceResult(
                model_name=model_name,
                segmentation=overlay_image,
                pred_mask=pred,
                metrics=metrics,
                class_distribution=class_dist,
                inference_time=inference_time
            )

        except Exception as e:
            print(f"æ¨¡å‹ {model_name} æ¨æ–­å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            # è¿”å›æ¨¡æ‹Ÿç»“æœ
            pred = np.zeros((512, 512), dtype=np.uint8)
            seg_colored = self.image_processor.colorize_segmentation(pred, self.dataset_type)

            original_image = Image.open(self.image_path).convert('RGB')
            original_image = original_image.resize((512, 512), Image.Resampling.LANCZOS)
            original_array = np.array(original_image)
            overlay_image = self.image_processor.create_overlay(original_array, seg_colored)

            return InferenceResult(
                model_name=model_name,
                segmentation=overlay_image,
                pred_mask=pred,
                metrics={'mIoU': 0.0, 'mAcc': 0.0, 'F1': 0.0},
                class_distribution=self.metrics_calculator.calculate_class_distribution(pred, num_classes),
                inference_time=0.0
            )