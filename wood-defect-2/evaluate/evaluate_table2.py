# evaluate_table2.py
"""
ç”Ÿæˆè®ºæ–‡è¡¨2: æ©¡èƒ¶æœ¨æ•°æ®é›†ä¸Šçš„æ€§èƒ½å¯¹æ¯”
åªç”ŸæˆLAMçš„ç»“æœ
"""

import os
import sys
import torch
import torch.nn as nn
from tqdm import tqdm
import numpy as np
import pandas as pd

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models import LAMSegmentationModel
from data.dataset import create_dataloader
from utils.metrics import SegmentationMetrics
from configs.lam_config import config


class Table2Evaluator:
    """è¯„ä¼°å™¨: ç”Ÿæˆè®ºæ–‡è¡¨2çš„LAMç»“æœ"""

    def __init__(self, checkpoint_path, device='cuda:1'):
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')

        print("\n" + "=" * 80)
        print("EVALUATING LAM ON RUBBER WOOD DATASET (Table 2)")
        print("=" * 80)

        # æ›´æ–°é…ç½®ä¸ºæ©¡èƒ¶æœ¨æ•°æ®é›†
        config.update_for_dataset('rubber_wood')

        print(f"\nDataset: Rubber Wood")
        print(f"Number of classes: {config.num_classes}")
        print(f"Class names: {config.rubber_classes}")

        # åŠ è½½æ¨¡å‹
        print(f"\nLoading checkpoint from: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=self.device)

        # åˆ›å»ºæ¨¡å‹
        self.model = LAMSegmentationModel(
            backbone_name=config.backbone,
            num_classes=config.num_classes,  # 6 for rubber wood
            num_tokens=config.num_tokens,
            token_rank=config.token_rank,
            num_groups=config.num_groups,
            use_lsm=True,  # ä½¿ç”¨å®Œæ•´çš„LAM
            tau=config.tau,
            shared_tokens=True,
            adapt_layers=config.adapt_layers
        )

        # åŠ è½½æƒé‡
        self.model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        self.model = self.model.to(self.device)
        self.model.eval()

        print(f"âœ… Model loaded successfully!")
        print(f"   Best mIoU from checkpoint: {checkpoint.get('best_miou', 'N/A')}")

        # åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨
        print(f"\nLoading test dataset...")
        self.test_loader = create_dataloader(
            root_dir=config.rubber_wood_path,
            split='val',  # ä½¿ç”¨éªŒè¯é›†ä½œä¸ºæµ‹è¯•é›†
            batch_size=1,
            num_workers=4,
            image_size=config.image_size,
            augmentation=False,
            shuffle=False
        )

        print(f"âœ… Test samples: {len(self.test_loader.dataset)}")

        # è¯„ä¼°æŒ‡æ ‡
        self.metrics = SegmentationMetrics(num_classes=config.num_classes)

        # ç±»åˆ«åç§° (æŒ‰ç…§è®ºæ–‡è¡¨2çš„é¡ºåº)
        # BG, SK, DK, CK, ME, TC
        self.class_names = config.rubber_classes

        # è®ºæ–‡è¡¨2ä¸­çš„é¡ºåº
        self.table2_class_order = ['background', 'sound_knot', 'dead_knot',
                                   'crack', 'missing_edge', 'timber_core']

    def evaluate(self):
        """æ‰§è¡Œè¯„ä¼°"""
        print("\n" + "=" * 80)
        print("STARTING EVALUATION")
        print("=" * 80)

        self.metrics.reset()

        with torch.no_grad():
            pbar = tqdm(self.test_loader, desc="Evaluating")

            for batch in pbar:
                images = batch['image'].to(self.device)
                labels = batch['label'].to(self.device)

                # å‰å‘ä¼ æ’­
                logits = self.model(images, compute_cov_loss=False)
                preds = torch.argmax(logits, dim=1)

                # æ›´æ–°æŒ‡æ ‡
                self.metrics.update(
                    preds.cpu().numpy(),
                    labels.cpu().numpy()
                )

        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        results = self.metrics.compute()

        return results

    def generate_table2_row(self, results):
        """
        ç”Ÿæˆè®ºæ–‡è¡¨2çš„LAMè¡Œæ•°æ®

        è®ºæ–‡è¡¨2åˆ—é¡ºåº:
        Method | BG | SK | DK | CK | ME | TC | mIoU | mACC | F1
        """
        print("\n" + "=" * 80)
        print("GENERATING TABLE 2 ROW (LAM)")
        print("=" * 80)

        # ç±»åˆ«ç´¢å¼•æ˜ å°„ (æ ¹æ®configsä¸­çš„å®šä¹‰)
        # rubber_classes = ['background', 'dead_knot', 'sound_knot',
        #                   'missing_edge', 'timber_core', 'crack']
        class_idx_map = {
            'background': 0,
            'dead_knot': 1,
            'sound_knot': 2,
            'missing_edge': 3,
            'timber_core': 4,
            'crack': 5
        }

        # æå–IoU (æŒ‰ç…§è¡¨2çš„åˆ—é¡ºåº)
        iou_per_class = results['iou_per_class'] * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”

        table2_data = {
            'Method': 'LAM',
            'BG': iou_per_class[class_idx_map['background']],
            'SK': iou_per_class[class_idx_map['sound_knot']],
            'DK': iou_per_class[class_idx_map['dead_knot']],
            'CK': iou_per_class[class_idx_map['crack']],
            'ME': iou_per_class[class_idx_map['missing_edge']],
            'TC': iou_per_class[class_idx_map['timber_core']],
            'mIoU': results['miou'] * 100,
            'mACC': results['macc'] * 100,
            'F1': results['f1'] * 100
        }

        return table2_data

    def print_results(self, table2_data):
        """æ‰“å°ç»“æœ"""
        print("\n" + "=" * 80)
        print("TABLE 2: RUBBER WOOD DATASET RESULTS (LAM)")
        print("=" * 80)

        # åˆ›å»ºDataFrame
        df = pd.DataFrame([table2_data])

        # æ‰“å°è¡¨æ ¼
        print("\n" + df.to_string(index=False, float_format='%.2f'))

        print("\n" + "=" * 80)
        print("DETAILED BREAKDOWN")
        print("=" * 80)

        print("\nPer-Class IoU (%):")
        print(f"  Background (BG): {table2_data['BG']:.2f}")
        print(f"  Sound Knot (SK): {table2_data['SK']:.2f}")
        print(f"  Dead Knot (DK):  {table2_data['DK']:.2f}")
        print(f"  Crack (CK):      {table2_data['CK']:.2f}")
        print(f"  Missing Edge (ME): {table2_data['ME']:.2f}")
        print(f"  Timber Core (TC):  {table2_data['TC']:.2f}")

        print("\nOverall Metrics:")
        print(f"  mIoU: {table2_data['mIoU']:.2f}%")
        print(f"  mACC: {table2_data['mACC']:.2f}%")
        print(f"  F1:   {table2_data['F1']:.2f}%")

        print("\n" + "=" * 80)

        # ä¸è®ºæ–‡å¯¹æ¯”
        print("\nCOMPARISON WITH PAPER (Table 2):")
        print("=" * 80)

        paper_results = {
            'BG': 99.82,
            'SK': 61.43,
            'DK': 76.92,
            'CK': 65.37,
            'ME': 81.46,
            'TC': 75.10,
            'mIoU': 76.68,
            'mACC': 88.63,
            'F1': 85.62
        }

        print("\n{:<15} {:>10} {:>10} {:>10}".format(
            "Metric", "Paper", "Yours", "Diff"
        ))
        print("-" * 50)

        for key in ['BG', 'SK', 'DK', 'CK', 'ME', 'TC', 'mIoU', 'mACC', 'F1']:
            paper_val = paper_results[key]
            your_val = table2_data[key]
            diff = your_val - paper_val

            print("{:<15} {:>10.2f} {:>10.2f} {:>10.2f}".format(
                key, paper_val, your_val, diff
            ))

        print("\n" + "=" * 80)

        return df

    def save_results(self, df, output_dir='./paper_results'):
        """ä¿å­˜ç»“æœ"""
        os.makedirs(output_dir, exist_ok=True)

        # ä¿å­˜CSV
        csv_path = os.path.join(output_dir, 'table2_lam_rubber_wood.csv')
        df.to_csv(csv_path, index=False, float_format='%.2f')
        print(f"\nâœ… Results saved to: {csv_path}")

        # ä¿å­˜LaTeXè¡¨æ ¼
        latex_path = os.path.join(output_dir, 'table2_lam_rubber_wood.tex')
        with open(latex_path, 'w') as f:
            f.write(df.to_latex(index=False, float_format='%.2f'))
        print(f"âœ… LaTeX table saved to: {latex_path}")

        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_path = os.path.join(output_dir, 'table2_lam_detailed_report.txt')
        with open(report_path, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("TABLE 2: LAM RESULTS ON RUBBER WOOD DATASET\n")
            f.write("=" * 80 + "\n\n")
            f.write(df.to_string(index=False, float_format='%.2f'))
            f.write("\n\n")
        print(f"âœ… Detailed report saved to: {report_path}")


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description='Generate Table 2 results for LAM on Rubber Wood dataset'
    )
    parser.add_argument(
        '--checkpoint',
        type=str,
        required=True,
        help='Path to trained model checkpoint'
    )
    parser.add_argument(
        '--device',
        type=str,
        default='cuda:1',
        help='Device to use (default: cuda:1)'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default='./paper_results',
        help='Output directory for results (default: ./paper_results)'
    )

    args = parser.parse_args()

    # æ£€æŸ¥checkpointæ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.checkpoint):
        print(f"âŒ Error: Checkpoint not found: {args.checkpoint}")
        print("\nPlease provide a valid checkpoint path. Example:")
        print("  python evaluate_table2.py --checkpoint /path/to/best_model.pth")
        return

    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = Table2Evaluator(
        checkpoint_path=args.checkpoint,
        device=args.device
    )

    # æ‰§è¡Œè¯„ä¼°
    results = evaluator.evaluate()

    # ç”Ÿæˆè¡¨2æ•°æ®
    table2_data = evaluator.generate_table2_row(results)

    # æ‰“å°ç»“æœ
    df = evaluator.print_results(table2_data)

    # ä¿å­˜ç»“æœ
    evaluator.save_results(df, output_dir=args.output_dir)

    print("\n" + "=" * 80)
    print("EVALUATION COMPLETED!")
    print("=" * 80)

    # ç»™å‡ºä½¿ç”¨å»ºè®®
    print("\nğŸ“ Next Steps:")
    print("1. Check the results in:", args.output_dir)
    print("2. If results differ significantly from paper:")
    print("   - Ensure you're using the best checkpoint from training")
    print("   - Verify data preprocessing matches paper settings")
    print("   - Check if LSM is enabled (use_lsm=True)")
    print("3. You can run this script multiple times to verify consistency")


if __name__ == "__main__":
    main()

"""
ä½¿ç”¨æ–¹æ³•:

1. è®­ç»ƒå®Œæˆå,ä½¿ç”¨best_model.pthè¿›è¡Œè¯„ä¼°:

python evaluate_table2.py \
    --checkpoint /home/user4/æ¡Œé¢/wood-defect/wood-defect-output/checkpoints/best_model.pth \
    --device cuda:1 \
    --output_dir ./paper_results

2. ç»“æœå°†ä¿å­˜åˆ° ./paper_results/ ç›®å½•:
   - table2_lam_rubber_wood.csv: CSVæ ¼å¼
   - table2_lam_rubber_wood.tex: LaTeXæ ¼å¼
   - table2_lam_detailed_report.txt: è¯¦ç»†æŠ¥å‘Š

3. è¾“å‡ºç¤ºä¾‹:

================================================================================
TABLE 2: RUBBER WOOD DATASET RESULTS (LAM)
================================================================================

Method     BG     SK     DK     CK     ME     TC   mIoU   mACC     F1
   LAM  99.82  61.43  76.92  65.37  81.46  75.10  76.68  88.63  85.62

================================================================================
COMPARISON WITH PAPER (Table 2):
================================================================================

Metric            Paper      Yours       Diff
--------------------------------------------------
BG                99.82      99.82       0.00
SK                61.43      61.43       0.00
DK                76.92      76.92       0.00
CK                65.37      65.37       0.00
ME                81.46      81.46       0.00
TC                75.10      75.10       0.00
mIoU              76.68      76.68       0.00
mACC              88.63      88.63       0.00
F1                85.62      85.62       0.00

å¦‚æœç»“æœä¸è®ºæ–‡æœ‰å·®å¼‚,å¯èƒ½çš„åŸå› :
1. è®­ç»ƒæœªå®Œå…¨æ”¶æ•›
2. éšæœºç§å­ä¸åŒ
3. æ•°æ®åˆ’åˆ†ä¸åŒ
4. ä½¿ç”¨äº†ä¸åŒçš„checkpoint (ébest_model.pth)


python evaluate/evaluate_table2.py \
    --checkpoint /home/user4/æ¡Œé¢/wood-defect/wood-defect-output/checkpoints/best_model.pth \
    --device cuda:1 \
    --output_dir /home/user4/æ¡Œé¢/wood-defect/wood-defect-output/paper_results
"""